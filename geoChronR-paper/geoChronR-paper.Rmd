---
title: GeoChronR -- an R framework to model and analyze age-uncertain paleogeoscientific timeseries.
journal: "`r rticles::copernicus_journal_abbreviations(journal_name = 'communication')`"
author:
  - given_name: Nicholas
    surname: McKay
    affiliation: 1
    email: Nicholas.McKay@nau.edu
    corresponding: true
  - given_name: Julien
    surname: Emile-Geay
    affiliation: 2
    email: julieneg@usc.edu
  - given_name: Deborah
    surname: Khider
    affiliation: 2
# If you have more than one corresponding author, add them manually using the following structure:
# Two authors: \correspondence{Daniel N端st (daniel.nuest@uni-muenster.de) and Josiah Carberry (j.carberry@orcid.org)}
# Three authors or more: \correspondence{Daniel N端st (daniel.nuest@uni-muenster.de), Josiah Carberry j.carberry@orcid.org), and Markus Konkol (m.konkol@wwu.de)}
# If the following line is uncommented, the "corresponding: true" above are ignored
#correspongdingauthors: Daniel N端st (daniel.nuest@uni-muenster.de) and Josiah Carberry (j.carberry@orcid.org)
affiliation:
  - code: 1
    address: School of Earth and Sustainability, Northern Arizona University, Flagstaff, AZ 86011
  - code: 2
    address: University of Southern California, Los Angeles, CA
abstract: |
  Chronological uncertainty is a hallmark of the paleosciences. While many tools have been made available to researchers to produce age models suitable for various settings and assumptions, disparate tools and output formats often discourage integrative approaches. In addition, propagating age model uncertainties to subsequent analyses, and visualizing the results, has received comparatively little attention in the literature and available software. Here we describe GeoChronR, an open-source R package to facilitate these tasks. GeoChronR is built around emerging data standards for the paleosciences (Linked Paleo Data, or LiPD), and offers access to four popular age modeling techniques (Bacon, BChron, Oxcal, BAM). The output of these models is easily stored in LiPD, enabling paleo-aware synchronization, regression, correlation, principal component, and spectral analyses. Five real-world use cases illustrate how to use GeoChronR to facilitate these tasks, and to visualize the results in intuitive ways. 
bibliography: geochronr.bib
running:
  title: The GeoChronR framework
  author: McKay et al.
competinginterests: |
  The authors declare no competing interests.
# OPTIONAL:
algorithms: true
# See https://publications.copernicus.org/for_authors/licence_and_copyright.html, normally used for transferring the copyright, if needed.
copyrightstatement: |
  The author's copyright for this publication is transferred to institution/company.
availability:
  #  use this to add a statement when having only software code available
  #  use this to add a statement when having only data sets available
  #  use this section when having geoscientific samples available
  #use this section when having video supplements available
  #code: |
  #data: |
  codedata: |
    use this to add a statement when having data sets and software code available
  #sample: |
  #videosupplement: |
  authorcontribution: |
    NPM did... JEG did a lot o cheerleading, created lots of bugs, but did manage to write one vignette. DK did...
disclaimer: |
  disc
acknowledgements: |
  ack
appendix: |
  \section{Figures and tables in appendices}
  \subsection{Option 1}
  If you sorted all figures and tables into the sections of the text, please also sort the appendix figures and appendix tables into the respective appendix sections.
  They will be correctly named automatically.
  \subsection{Option 2}
  If you put all figures after the reference list, please insert appendix tables and figures after the normal tables and figures.
  Regarding figures and tables in appendices, the following two options are possible depending on your general handling of figures and tables in the manuscript environment:
  `\appendixfigures` needs to be added in front of appendix figures
  `\appendixtables` needs to be added in front of appendix tables
  To rename them correctly to A1, A2, etc., please add the following commands in front of them:
  Please add `\clearpage` between each table and/or figure. Further guidelines on figures and tables can be found below.
output:
  bookdown::pdf_book:
     base_format: rticles::copernicus_article # for using bookdown features like \@ref()
  rticles::copernicus_article: default
---

\introduction

<!-- Introduction text goes here. -->
<!-- You can change the name of the section if neccessary using `\introduction[modified heading]`. -->

<!-- The following settings can or must be configured in the header of this file and are bespoke for Copernicus manuscripts: -->

<!-- - The `journal` you are submitting to using the official abbreviation. You can use the function `rticles::copernicus_journal_abbreviations(name = '...')` to search the existing journals. -->

<!-- - Specific sections of the manuscript: -->

<!--   - `running` with `title` and `author` -->

<!--   - `competinginterests` -->

<!--   - `copyrightstatement` (optional) -->

<!--   - `availability` (strongly recommended if any used), one of `code`, `data`, or `codedata` -->

<!--   - `authorcontribution` -->

<!--   - `disclaimer` -->

<!--   - `acknowledgements` -->

<!-- See the defaults and examples from the skeleton and the official Copernicus documentation for details. -->

<!-- **Important**: Always double-check with the official manuscript preparation guidelines at [https://publications.copernicus.org/for_authors/manuscript_preparation.html](https://publications.copernicus.org/for_authors/manuscript_preparation.html), especially the sections "Technical instructions for LaTeX" and "Manuscript composition". -->
<!-- Please contact Daniel N端st, `daniel.nuest@uni-muenster.de`, with any problems. -->

## Background


Quantifying chronological uncertainties, and how they might influence the understanding of past changes is fundamental to the paleogeosciences. 
Without robust error determination, it is impossible to properly assess the extent to which past changes occurred simultaneously across regions or the duration of abrupt events, both of which limit our capacity to apply paleoscientific understanding to modern and future processes.
The need for better infrastructure to both characterize uncertainty, and to explicitly evaluate how age uncertainty impacts the the interpretation of records of past climate, ecology or landscapes, has been long recognized [@Noren2013, (more)]. 
In response to this need, the paleogeoscience community has made substantial advances toward improving geochronological accuracy by:

1. Improving analytical techniques that allow for more precise age determination on smaller and context-specific samples [@Brown_radiocarbon89,@Eglinton96,@Fifield2000,@Eggins2005,@Santos_blank_2010]

2. Refining our understanding of how past changes in the Earth system impact the age accuracy, for example: improvements to the radiocarbon calibration curve [@Stuiver91,@Stuiver98,intcal references] and advances in our understanding of spatial variability in cosmogenic production rates used in exposure dating [@Balco2009,@Masarik2009]

3. Dramatic improvement in the level of sophistication and realism in age-depth models used to estimate the ages of sequences between dated samples [e.g. @Ramsey2009Bayesian, @parnell2008flexible, @Blaauw2010CLAM, @Blaauw2011BACON].

Over the past 20 years, these advances have been widely adopted in the paleogeosciences. 
However, despite the progress made in quantifying uncertainty in ages and in age models, few studies have formally evaluated how chronological uncertainty may have affected their results. 
For instance, whereas the algorithms presented by [@Ramsey2009Bayesian, @parnell2008flexible, @Blaauw2010CLAM, @Blaauw2011BACON] have been broadly used, the overwhelming majority of these studies calculate the single best-estimate model (often a median or mean), use this model to put measured paleoclimatic or paleoenvironmental data on a timescale, and then proceed to analyze the record with little to no reference to the age modeling exercise [@McKay2008,@McKay2009]. 
Typically, any discussions of chronological uncertainties remain qualitative.

This paradigm is beginning to change. 
In recent years a handful of studies have taken advantage of approaches that generate ensembles of age models to evaluate how the results of their analyses and conclusions vary given differences between ensemble members [@Haam_Huybers2010,@Rhines_JGR2011,@Anchukaitis_Tierney2012,@Shakun_Nature2012,@Marcott_Science2013, @Tierney2013]. 
By using each ensemble age model to create a time-uncertain ensemble records, and then carrying that ensemble through the analysis, the precise impact of age uncertainty can be formally evaluated. 
This approach, of course, does not address all aspects of uncertainty, but it does offer the broad potential to ascertain which results are robust to chronological uncertainty, and which are not.

Despite its potential to substantially improve uncertainty quantification for the paleogeosciences, this framework is not widely utilized. 
The majority of studies utilizing this approach have been regional [e.g., @Anchukaitis_Tierney2012,@Tierney2013,@mckay_onset_2018, @routson2018} or global-scale [e.g., @Shakun_Nature2012,@Marcott_Science2013,@kaufman2020HoloceneGMST] syntheses.
Occasionally, primary publications of new records incorporate time-unceratin analysis into their studies [@Boldt2015,more], but this remains rare. 
We suggest that there are several reasons for the lack of adoption of these techniques:

1. For synthesis studies, the necessary geochronological data are not publicly available for the vast majority of records. Even when they are available, the data are archived in diverse and unstructured data formats. Together, this makes what should be a simple process of aggregating and preparing data for analysis prohibitively time-consuming;

2. For studies of new and individual records, few tools for ensemble analysis are available, and those that are require a degree of comfort with coding languages and scientific programming that is rare among paleogeoscientists;

3. There is a disconnect between age-model development and time-uncertain analysis. Published approaches have utilized either simplified age-modeling approaches [@Haam_Huybers2010], or specialized approaches not used elsewhere in the community [@Shakun_Nature2012,@Anchukaitis_Tierney2012,@Marcott_Science2013,@Tierney2013,@routson2018]. 

Extracting the relevant data from commonly-used age-modelling algorithms, creating time-uncertain ensembles, then reformatting those data for analysis in available tools typically requires the development of extensive custom codesets. 

## Motivation

GeoChronR is built to lower the barriers to broader adoption of these emerging methods.
It provides an easily-accessibly, open-source and extenisble software package of industry-standard and cutting-edge tools that provides users a single environment to create, analyse, and visualize time-uncertain data.
GeoChronR is designed around emerging standards in the paleogeosciences that connects users to growing libraries of standardized datasets formatted in the Linked PaleoData format [@LiPD] and [@neotoma].

## Outline of manuscript

This manuscript describes the design, analytical underpinnings and most common use cases of GeoChronR.
Section \@ref(sec:age-modeling) describes the integration of age modelling algorithms with GeoChronR.
Section \@ref(sec:age-uncertain-analysis) details the methods implemented for age uncertain analysis.
Section \@ref(sec:visualization) goes through the principles and implementation of age-uncertain data visualization in GeoChronR, and section \@ref(sec:use-cases) provides five real-world examples of how GeoChronR can be used for scientific workflows.


<!-- Age modeling section -->


# Age Uncertainty Quantification in GeoChronR {#sec:age-modeling}

GeoChronR does not provide any new approaches to age uncertainty quantification, rather, it integrates with existing and widely-used packages while streamlining the acquisition of age ensemble members. 
Fundamentally, there are two types of age models used in the paleogeosciences: tie-point and layer-counted. 
Most of the effort in age uncertainty quantification in the community has been focused on tie-point modelling, where the goal is to estimate ages (and their uncertainties) along a depth profile given the constraints of known ages (and their uncertainties) at multiple depths through the section.
Over the past 20 years, these algorithms have progressed from linear or polynomial regressions with simple characterizations of uncertainty to more sophisticated techniques [@clam, @heegaard05]. 
More recently, there has been a convergence towards Bayesian techinques.
As of 2020, the three most widely used algorithms are Bacon [@bacon], BChron [@parnell2008flexible], and OxCal [@ramsey2008deposition], which are all Bayesian age-deposition models that estimate posteriors on age-depth relationships with different assumptions and methodologies.
@trachsel2017 reviewed the performance of these three algorithms, as well as a non-Bayesian approach [@clam], and found that the three Bayesian approaches generally outperform previous algorithms, especially when appropriate parameters are chosen (although choosing appropriate parameters can be challenging).
All three Bayesian modelling algorithms use Markov Chain Monte Carlo (MCMC) techniques to quantify their posterior distributions and to estimate age-uncertainty distributions as a function of depth in the section.
GeoChronR interfaces with each of these algorithms through their R packages (cite R Packages), and streamlines data input and the extraction of the age ensembles from the MCMC results for further analysis.

In addition to working with ensembles from tie-point age models, GeoChronR connects users to ensembles generated for layer-counted models. 
BAM [@BAM] was designed to probabilistically simulate counting uncertainty in banded archives, such as corals, ice cores, or varved sediments, but can also be used to simulate age uncertainty for any record, and is useful when the data or metadata required to calculate an age-depth model are unavailable.
Here we briefly describe the theoretical basis and applications of each of the four approaches integrated in GeoChronR. 

## Bacon

The Bayesian ACcumulatiON (Bacon) algorithm  [@bacon] is one of the most broadly used age-modelling techniques, and was designed to take advantage of prior knowledge about the distribution and autocorrelation structure of sedimentation rates in a sequence to better quantify uncertainty between dated levels.
The algorithm employs an adaptive Markov Chain Monte Carlo algorithm that allows for Bayesian learning to update the sedimentation rate distribution. 
Bacon has two key parameters: the shape of the accumulation prior, and the segment length, which can interact in complicaed ways [@trachsel2017]. 
In our experience, the segment length parameter has the greatest impact on the ultimate shape and amount of uncertainty simulated by Bacon, as larger segments result in increased flexibility of the age-depth curve, and increased uncertainty between dated levels. 
Bacon is written in C++ and R, with an R interface.
More recently, the authors released an R package `rbacon` [@baconPackage], which GeoChronR leverages to provide access to the algorithm.
Bacon will optionally return a subset of the MCMC accumulation rate ensemble members with high *a posteriori* probabilities, which GeoChronR uses to form age ensemble members for subsequent analysis. 

## BChron

{Deborah}


## Oxcal

The OxCal software package has a long history and extensive tools for the statistical treatment of radiocarbon and other geochronological data (cite a bunch of bronk ramsey).
In @ramsey2008deposition, age-depth modelling was introduced with three options for modelling depositional processes that are typically useful for sedimentary sequences: uniform, varve, and Poisson deposition models, laveled U-sequence, V-sequence and P-sequence, respectively.
The Poisson-based model is the most broadly applicable for sedimentary, or other accumulation-based archives (e.g. speleothems), and although any sequence type can be used in GeoChronR, most users will use a P-sequence, which is the default. 
Analagously to segment length parameter in Bacon, the *k* parameter (called "eventsPerUnitLength" in GeoChronR), controls how many events are simulated per unit of depth, and has a strong impact on the flexibility of the model, as well as the amplitude of the resulting uncertainty. 
As the number of events increases, the flexibility of the model, and the uncertainties decrease.
@trachsel2017 found that this parameter has large impact on the accuracy of the model, and moreso than the choices made in Bacon or Bchron.
Fortunately, @bronkramsey2010 made it possible for *k* to be treated as a variable, and the model will estimate the most likely values of *k* given a prior estimate and the data, however this calculation can greatly increase the convergence time of the model.
Oxcal is written in C++, with an interface in R [@oxcAAR].
Oxcal doesn't calculate posterior ensembles for a depth sequence, but can optionally output MCMC posteriors at specified levels in the sequence.
GeoChronR uses this feature to extract ensemble members for subsequent analysis. 


## Banded Age Model (BAM)

{Julien}

<!-- Analysis section -->


# Age-uncertain data analysis in GeoChronR {#sec:age-uncertain-analysis}

Very little theoretical work has been done on how uncertainty in time impacts various analyses, and such an approach remains impractical given the variable nuances of age-uncertainty structures in realistic paleogeoscientific data.
Consequently, GeoChronR follows a pragmatic and broadly-used approach that uses age ensembles, and optionally ensembles in climate proxy or paleoenvironmental data, to propagate uncertainties through all steps of an analysis.
Effectively, this is done by randomly sampling from the ensemble(s) and then repeating the analysis hundreds or thousands of times to build an output ensemble that quantifies the impact of those uncertainties on a particular analytical result.
These output ensembles often do not lend themselves to binary significance statistics (e.g., p < 0.05), but are readily used to provide quantiles that estimate probability density ranges, and can provide strong evidence for which results are robust to age and proxy and uncertainty (and which are not).
Version 1.0.0 of GeoChronR has implemented ensemble analytical techniques for four of the most common analyses in the paleogeosciences, the details of which are described below.


## Correlation
Pearson correlation is a straightforward and widely used technique to quantify the covariability of two timeseries with arbitrary units.
The computation is fast, and lends itself well to ensemble analysis, with a handful of pretreatment and significance considerations that are relevant for ensembles of paleogeoscientific data.
First, correlation analysis for timeseries is built on the assumption the datasets can be aligned on a common timeline.
Age-uncertain data violate this assumption.
We overcome this by treating each ensemble member from one or more age uncertain timeseries as valid for that iteration, then "bin" each of the timeseries into coeval intervals.
The "binning" procedure in GeoChronR sets up an interval, which is typical evenly spaced, over which the data are averaged.
Generally, this intentionally degrades the median resolution of the timeseries, for example, a timeseries with 37-year median spacing could be reasonably "binned" into 100- or 200-year bins.
The binning procedure is repeated for each ensemble member, meaning that between different ensembles, different observations will be placed in different bins.

Following binning, Pearson correlation is calculated and recorded for each ensemble member. 
In addition to the correlation coefficients, GeoChronR calculates significance values for each correlation. 
Paleogeoscientific timeseries are often highly autocorrelated, which cnan lead to spurious correlation. 
Therefore, in addition to the standard Student's T-test p-value calculation, we also calculate an p-value that is adjusted for autocorrelation to reflect the reduction in degrees of freedom due to autocorrelation following @bretherton1999.
As an additional option, we also calculate the effect of false discovery rate (FDR) on the p-values... **Julien**

## Regression

Linear regression is a commonly used tool to model the relationships between paleogeoscientific data and instrumental or other datasets.
One application is calibration-in-time [references], whereby a proxy timeseries is calibrated to an instrumental series with a linear regression model over their period of overlap.
This approach is particularly vulnerable to age uncertainties, as both the development of the relationship, and the reconstruction, are affected. 
GeoChronR propagates age (and optionally proxy) uncertainties through both the fitting of the ordinary least squares regression model, and the reconstruction "forecast" using the ensemble model results and age uncertainty.
Like the correlation algorithm, ensemble regression uses an ensemble binning procedure that's analgous to correlation.
GeoChronR then exports uncertainty structure of the modeled parameters (e.g. slope and intercept), as well as the ensemble of reconstructed calibrated data through time. 

## Principal Component Analysis

GeoChronR implements the age-uncertain principal component analysis (PCA) procedure introduced by @anchukaitis2013mceof, with some minor modifications and additions.
Like correlation and regression, PCA (or empirical orthogonal function {EOF} analysis) requires temporally aligned observations, and GeoChronR uses a binning procedure to achieve this across multiple ensembles.
This differs from the implementation of @anchukaitis2013mceof, who interpolated the data to a common timestep.
In addition, traditional singular value decomposition approaches to PCA require a complete set of observations without any missing values. 
For paleoclimate data, especially when considering age uncertainty, this requirement is often prohibitive. 
To overcome this, GeoChronR implements multiple options for PCA analysis using the `pcaMethods` package.
The default and most rigorously tested option is a probabilistic PCA (PPCA) approach that uses expectation maximization algorithms to infill missing values [@roweis1998algorithms]. 
This algorithm assumes that the data and their uncertainties are normally distributed, which is often (but not always) a reasonable assumption for paleogeoscientific data. 
As in correlation and regression, GeoChronR propagates uncertainties through the analysis by repeating the analysis across randomly sampled age and/or proxy ensemble members to build output ensembles of the loadings (eigenvectors), variance explained (eigenvalues) and principal component timeseries.
Because the sign of the loadings in PCA analyses is arbitrary and vulnerable to small changes in the input data, GeoChronR reorients the sign of the loadings for all PCs so that the mean of the loadings is positive. 
For well defined modes this effectively orients ensemble PCs, but loading orientation may be uncertain for lower order, or more uncertain, modes.


## Spectral Analysis

**Julien**

<!-- Viz section -->

# Visualization with GeoChronR {#sec:visualization}

One of the challenges with age-uncertain analysis is that it adds at least one additional dimension to the results, which can be challenging to visualize.
GeoChronR aims to facilitate simple creation of intuitive, publication-quality figures that provide multiple options for visualizing the impacts of age-uncertainty, while maintaining flexibility for users to customize their results as needed.
To meet the multiple constraints of simplicity, quality and customization, GeoChronR relies heavily on the `ggplot2` package [@ggplot2].
High-level plotting functions in GeoChronR (e.g., `plotTimeseriesEnsRibbons` and `plotPca`) produce complete figures as `ggplot2` objects, that can be readily customized by adding or changing `ggplot2` layers.
The figures in the Use Cases section (Section \@(sec:use-cases)) are all produced directly from GeoChronR without modification and generally fall into a few categories.

### Timeseries

Most of the figures that GeoChronR produces are ensemble timeseries.
GeoChronR uses two complementary approaches to visualize these ensembles.
The first is the simplest, where a large subset of the ensemble members are plotted as semi-transparent lines.
This approach, implemented in `plotTimeseriesEnsLines`, provides a faithful representation of the data, while the overlapping semi transparency provides a qualitative sense of the ensemble uncertainty structure.
The second approach uses contours to more rigorlously visualize the structure of the time-value uncertainty space represented by the ensembles.
`plotTimeseriesEnsRibbons` shows the quantiles of the ensembles at specified levels as shaded bands. 
This approach provides the quantitative uncertainty structure, but tends to smooth out the apparent temporal evolution of the data. 
Fortunately, the two approaches are complementary, and often the best approach is to quantify the ensemble distribution with ribbons in the background, and then overlap them with a handful of ensemble lines to illustrate the structure in representive ensemble members.

### Geospatial

GeoChronR has simple mapping capabilities built in that rely on the `maps` [@maps] and `ggmap` [@ggmap] packages.
The `mapLipd` and `mapTs` functions provide quick geospatial visualization of one or more datasets, but also serve as the basis for the visualization of ensemble spatial data produced by ensemble PCA analyses.
In paleogeoscientific studies, the loadings (eigenvectors) of a PCA analysis are often portrayed as dots on a map, with a colorscale that highlights the sign and amplitude of the loadings.
In ensemble PCA, the additional dimension of uncertainty in the loadings needs to be visualized as well. 
In GeoChronR, the median of the loadings is shown as a color, and the size of the symbol is inversely proportional to the spread of uncertainty across the ensemble.
Consequently, large symbols depict loadings that are robust to the uncertainties, whereas small symbols show datasets whose loadings change substantially across the analysis.
An example is shown in Section \@(sec:pca)

### Spectral Analysis



# Use cases {#sec:use-cases}

We now illustrate the use of these tools on four use cases. The first example shows how to create age ensembles on different archives, and how to visualize the timing of abrupt events with appropriate uncertainty quantification. The second example shows how to quantify similarities in age-uncertain records. The third introduces the topic of age-uncertain calibrations, the fourth quantifies multivariate relationships using principal components analyses, and the fifth deal with spectral analysis. 


## Creating an age ensemble 

A common first task when using geoChronR is to create an age ensemble, either because the user is developing a new record, or because the age ensemble data for the record they are interested is unavailable.
As described in section X.Y workflows for four published age quantification programs are integrated into geoChronR.
All four methods are mostly simply used in geoChronR with a LiPD file that contains the chronological measurements, and the functions `runBacon(L)`, `runBchron(L)`, `runOxcal(L)` and `runBam(L)`.
These functions take LiPD objects as inputs, and return updated LiPD objects that include age-ensemble data generated by the respective software packages.
Typically, additional parameters are needed for to optimally run the algorithms.
When these parameters are not included, geoChronR will run in interactive mode, asking the user which variables and parameters they would like to model.
These parameter choices are printed to the screen during while the program runs, or are available later with the function `getLastVarString()`.
By specifying these parameters, age model creation can be scripted and will run in non-interactive mode.
In this use case, we'll use geoChronR and BChron [@parnell2008flexible] to calculate an age ensemble for the Hulu Cave $\delta^{18}$O speleothem record [@hulu2001], and BAM [@BAM] to simulate age uncertainties for the GISP2 ice core $\delta^{18}$O dataset [@alley].
The `plotChronEns(hulu)` function will plot an age-depth model and uncertainties derived from the age ensemble.

```{r, echo=FALSE,results='hide',warning = FALSE, message = FALSE}
## ---- results = FALSE, warning = FALSE, message= FALSE------------------------
library(lipdR)
library(geoChronR)
library(magrittr)
library(ggplot2)
library(dplyr)
library(purrr)
```

```{r, echo=FALSE,results='hide',warning = FALSE, message = FALSE,cache=TRUE}
hulu <- lipdR::readLipd("http://lipdverse.org/geoChronR-examples/Hulucave.Wang.2001.lpd")

hulu <- runBchron(hulu,
                  cal.curves = "normal",
                  iter = 10000,
                  extractDate = 10000,
                  which.table = 2,
                  lab.id.var = NULL,
                  age.var = 'age',
                  age.uncertainty.var = 'ageUncertaintyHigh',
                  age.14c.var = NULL,
                  age.14c.uncertainty.var =  NULL,
                  depth.var = 'depth',
                  reservoir.age.14c.var = NULL,
                  reservoir.age.14c.uncertainty.var = NULL,
                  rejected.ages.var = NULL)
```

```{r, echo=FALSE,results='hide',warning = FALSE, message = FALSE}
chronPlot <- plotChronEns(hulu,truncate.dist = 1e-4)+ggtitle(NULL)
```

```{r,echo = FALSE,warning=FALSE,message = FALSE,fig.cap = "Need to write a caption"}
print(chronPlot)
```

After an age ensemble has been added to a LiPD object, the user can visualize the ensemble timeseries using `plotTimeseriesEnsRibbons()` and `plotTimeseriesEnsLines()`.
GISP2 $\delta^{18}$O is plotted with age uncertainty, using both functions, in figure x.

```{r, echo=FALSE,results='hide',warning = FALSE, message = FALSE, cache= TRUE}
gisp2 <- lipdR::readLipd("http://lipdverse.org/geoChronR-examples/GISP2.Alley.2000.lpd")

gisp2 <- runBam(gisp2,
               paleo.num = 1,
               paleo.meas.table.num = 1,
               chron.num = 1,
               model.num = 1,
               ens.table.number = 1,
               make.new = T,
               n.ens = 1000,
               model = list(name = "poisson",
                            param = 0.02,
                            resize = 0,
                            ns = 1000)
               )
gisp2.d18O <- selectData(gisp2,var.name = "temp")

gisp2.ens <- selectData(gisp2,var.name = "yearEnsemble")
gisp2.ens <- convertAD2BP(gisp2.ens)
```



```{r,echo = FALSE,warning=FALSE,message = FALSE,fig.cap = "Need to write a caption"}
plotTimeseriesEnsRibbons(X = gisp2.ens,Y = gisp2.d18O,n.bins = 500) %>% 
  plotTimeseriesEnsLines(X = gisp2.ens,Y = gisp2.d18O,n.ens.plot = 5,color = "Reds",alp = .2)+
  ggtitle(NULL)
```

## Correlation

Now that the user has generated age ensembles for the two datasets, they're interested to see if a correlation between the two datasets is robust to the age uncertainty modeled here.
On multi-millennial timescales, the two datasets have similarities, and previous work has suggested that could events during the Last Glacial period, which are observed in the GISP2 record, can impact the Asian Monsoon and be observed is speleothem records such as the Hulu Cave dataset. (NM: add references here and flesh out background)
The `corEns()` function in geoChronR will calculate ensemble correlations across age-uncertain datasets, such as these.
`corEns()` will also sample across ensembles in the paleoData as well, if present.
Here we calculate correlations during the period of overlap in 500 yr steps, determining significance for each pair of ensemble members while accounting for autocorrelation.

```{r, echo=FALSE,results='hide',warning = FALSE, message = FALSE,cache = TRUE}
hulu <- mapAgeEnsembleToPaleoData(hulu,age.var = "ageEnsemble",paleo.meas.table.num = 2)
hulu.ae <- selectData(hulu,var.name = "ageEnsemble",meas.table.num = 2)
hulu.d18O<- selectData(hulu,var.name = "d18O",meas.table.num = 2)
corout <- corEns(gisp2.ens,gisp2.d18O,hulu.ae,hulu.d18O,bin.step = 500,max.ens = 100)
corPlot <- plotCorEns(corout,legend.position = c(0.1, 0.8),significance.option = "autocorr")
```

The results show consistently negative correlations, although `r sum(corout$cor.df$r>0)/nrow(corout$cor.df)*100`% of the ensemble members are positive.
However, only `r sum(corout$cor.df$pSerial < 0.05)/nrow(corout$cor.df)*100`% are significant after accounting for serial autocorrelation.

```{r,echo = FALSE,warning=FALSE,message = FALSE,fig.cap = "Need to write a caption"}
print(corPlot)+ggtitle(NULL)
```


In this use case, we demonstrate how a user could calculate and visualize and age-uncertain correlation between the Hulu speleothem $\delta^{18}\mathrm{O}$ record and the GISP2 ice core $\delta^{18}\mathrm{O}$ record. (Introduction about why a user might want to do an age uncertain correlation between Hulu and GISP2).


## Age-uncertain Calibration
A natural extension of ensemble correlation is ensemble regression.
Although there are use cases where regressing one age-uncertain variable onto another is called for, here we regress an age-uncertain paleoclimate proxy onto time-certain instrumental to develop a calibration-in-time.
For this use case, we reproduce the results of @Boldt:2015, where the authors calibrate a spectral reflectance measure of chlorophyll abundance to temperature in Northern Alaska.

```{r, echo=FALSE,results='hide',warning = FALSE, message = FALSE, cache = TRUE}
  library(readr)
K <- lipdR::readLipd("http://lipdverse.org/geochronr-examples/Kurupa.Boldt.2015.ens.lpd")
K <- mapAgeEnsembleToPaleoData(K,age.var = "ageEnsemble")
kae <-  selectData(K,"ageEnsemble")
rabd <- selectData(K,"RABD")
kurupa.instrumental <- readr::read_csv("http://lipdverse.org/geochronr-examples/KurupaInstrumental.csv")
kae = convertBP2AD(kae)

kyear = list()
kyear$values = kurupa.instrumental[,1]
kyear$variableName = "year"
kyear$units = "AD"

kinst = list()
kinst$values = kurupa.instrumental[,2]
kinst$variableName = "Temperature"
kinst$units = "deg (C)"

regout = regressEns(time.x = kae,
                    values.x = rabd,
                    time.y =kyear,
                    values.y =kinst,
                    bin.step=3,
                    recon.bin.vec = seq(-4010,2010,by=20),
                    percentiles = c(5,50,95))
```

```{r,echo = FALSE,warning=FALSE,message = FALSE,fig.cap = "Need to write a caption"}
regPlots <- plotRegressEns(regout,alp = 0.01,font.size = 8)
```
Figure captions.

## Principle Component Analysis {sec:pca}

Thus far, the use cases have highlighted age-uncertain analyses of one or two sites, however quantifying the effects of age uncertainty can be even more impactful over large spatial datasets. 
Here we showcase how to use geoChronR to perform age-uncertain principle components analysis (PCA), also known as Monte Carlo Empirical Orthogonal Function (MCEOF) analysis, pioneered by @anchukaitis2013mceof.
In this example, we examine the Arctic 2k database [@McKayKaufman2014].

```{r, echo=FALSE,results='hide',warning = FALSE, message = FALSE, cache = TRUE}
FD <- readLipd("http://lipdverse.org/geoChronR-examples/arc2k/Arctic2k.zip") 
FD2 = purrr::map(FD,
                 mapAgeEnsembleToPaleoData,
                 strict.search = TRUE,
                 age.var = "ageEnsemble",
                 depth.var = NULL )
TS = extractTs(FD2)
TS.filtered = filterTs(TS,"interpretation1_variable == T")
tidyDf <- tidyTs(TS.filtered)
```

```{r,echo = FALSE,warning = FALSE, message = FALSE,fig.cap = "Need to write a caption"}

plotTimeseriesStack(tidyDf, 
                    color.var = "paleoData_variableName", 
                    color.ramp = c("DarkBlue","Orange","Black","Dark Green"),
                    line.size = .1, 
                    fill.alpha = .05,
                    lab.size = 2,
                    lab.space = 3)
```

```{r, echo=FALSE,results='hide',warning = FALSE, message = FALSE, cache = TRUE}

binned.TS = binTs(TS.filtered,bin.vec = seq(1400,2000,by=5),time.var = "ageEnsemble")
pcout = pcaEns(binned.TS)


```



```{r,echo = FALSE,warning = FALSE, message = FALSE,fig.cap = "Need to write a caption"}
plotPCA <- plotPcaEns(pcout,TS = TS.filtered,map.type = "line",projection = "stereo",bound.circ = T,restrict.map.range = T,f=.1,legend.position = c(0.5,.6),which.pcs = 1:2,which.leg = 2)
```

## Spectral Analysis


# Conclusion
I wrote a strawman for this section. Please feel free to edit/modify and extend.

Version 1.0.0 of GeoChronR provides user-friendly access to common age-uncertain analyses in the paleogeosciences, along with intuitive visualization of the results. 
Although the focus has been on simplicity and ease-of-use, the GeoChronR also has the underlying infrastructure to support customized analyses for users seeking to address a more nuanced or complex question. 
Nevertheless, in many ways the paleogeoscience community is only scratching the surface with age-uncertain analysis, and we look forward to working with the community to extend and expand the package. 
Looking forward, we suggest that the next major direction for age-uncertain analysis is philosophical, not technical.
Thus far, the community (and GeoChronR) has focused on quantifying the range of possibilities presented by age-uncertainty, not on developing approaches to constrain which ensemble members are most likely. 
Theoretically, additional information from nearby records, forcings or covariance structures could do so, but little has been done to date [@wernerAndTingley ]. 

GeoChronR is open-source community-sofware, and has benefitted substantially from multiple contributors and input from early adopters and workshop participants. 
We welcome feedback and strongly encourage contributions and enhancements. 



<!-- End of manuscript -->



<!-- Everything below are useful examples of how to use RMarkdown -->


Subsection text here.

### Subsubsection Heading Here

Subsubsection text here.

# Content section with citations

See the [R Markdown docs for bibliographies and citations](http://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html).

Copernicus supports biblatex. I put the .bib entries from the Paleocube proposal into `geochronr.bib`. Citations work like this:

Read [@Evans_QSR13], and [see @PRYSM].

# Content section with R code chunks

```{r, echo = FALSE}
sum <- 1 + 41
```

You should always use `echo = FALSE` on R Markdown code blocks as they add formatting and styling not desired by Copernicus.
The hidden workflow results in `r sum`.

You can add verbatim code snippets without extra styles by using ` ``` ` without additional instructions.

```
sum <- 1 + 41
```

# Content section with list

If you want to insert a list, you must

- leave

- empty lines

- between each list item


```
- leave

- empty lines

- between each list item
```

# Examples from the official template

## FIGURES

When figures and tables are placed at the end of the MS (article in one-column style), please add \clearpage between bibliography and first table and/or figure as well as between each table and/or figure.

### ONE-COLUMN FIGURES

Include a 12cm width figure of Nikolaus Copernicus from [Wikipedia](https://en.wikipedia.org/wiki/File:Nikolaus_Kopernikus.jpg) with caption using R Markdown.

```{r, out.width = "8.3cm", echo = FALSE, fig.cap = "one column figure"}
knitr::include_graphics("Nikolaus_Kopernikus.jpg")
```

### TWO-COLUMN FIGURES

You can also include a larger figure.

```{r, out.width = "12cm", echo = FALSE, fig.cap = "two column figure"}
knitr::include_graphics("Nikolaus_Kopernikus.jpg")
```

## TABLES

You can ad \LaTeX table in an R Markdown document to meet the template requirements.

### ONE-COLUMN TABLE

\begin{table}[t]
\caption{TEXT}
\begin{tabular}{l c r}
\tophline

a & b & c \\
\middlehline
1 & 2 & 3 \\

\bottomhline
\end{tabular}
\belowtable{Table Footnotes}
\end{table}

### TWO-COLUMN TABLE

\begin{table*}[t]
\caption{TEXT}
\begin{tabular}{l c r}
\tophline

a & b & c \\
\middlehline
1 & 2 & 3 \\

\bottomhline
\end{tabular}
\belowtable{Table footnotes}
\end{table*}

## MATHEMATICAL EXPRESSIONS

All papers typeset by Copernicus Publications follow the math typesetting regulations given by the IUPAC Green Book (IUPAC: Quantities, Units and Symbols in Physical Chemistry, 2nd Edn., Blackwell Science, available at: http://old.iupac.org/publications/books/gbook/green_book_2ed.pdf, 1993).

Physical quantities/variables are typeset in italic font (t for time, T for Temperature)

Indices which are not defined are typeset in italic font (x, y, z, a, b, c)

Items/objects which are defined are typeset in roman font (Car A, Car B)

Descriptions/specifications which are defined by itself are typeset in roman font (abs, rel, ref, tot, net, ice)

Abbreviations from 2 letters are typeset in roman font (RH, LAI)

Vectors are identified in bold italic font using \vec{x}

Matrices are identified in bold roman font

Multiplication signs are typeset using the LaTeX commands `\times` (for vector products, grids, and exponential notations) or `\cdot`

The character * should not be applied as mutliplication sign

## EQUATIONS

### Single-row equation

Unnumbered equations (i.e. using `$$` and getting inline preview in RStudio) are not supported by Copernicus.

\begin{equation}
1 \times 1 \cdot 1 = 42
\end{equation}

\begin{equation}
A = \pi r^2
\end{equation}

\begin{equation}
x=\frac{2b\pm\sqrt{b^{2}-4ac}}{2c}.  
\end{equation}

### Multiline equation

\begin{align}
& 3 + 5 = 8\\
& 3 + 5 = 8\\
& 3 + 5 = 8
\end{align}

## MATRICES

$$
\begin{matrix}
x & y & z\\
x & y & z\\
x & y & z\\
\end{matrix}
$$

## ALGORITHM

If you want to use algorithms, you can either enable the required packages in the header (the default, see `algorithms: true`), or make sure yourself that the \LaTeX packages `algorithms` and `algorithmicx` are installed so that `algorithm.sty` respectively `algorithmic.sty` can be loaded by the Copernicus template.
Copernicus staff will remove all undesirable packages from your LaTeX source code, so please stick to using the header option, which only adds the two acceptable packages.

\begin{algorithm}
\caption{Algorithm Caption}
\label{a1}
\begin{algorithmic}
\STATE $i\gets 10$
\IF {$i\geq 5$}
        \STATE $i\gets i-1$
\ELSE
        \IF {$i\leq 3$}
                \STATE $i\gets i+2$
        \ENDIF
\ENDIF
\end{algorithmic}
\end{algorithm}

## CHEMICAL FORMULAS AND REACTIONS

For formulas embedded in the text, please use `\chem{}`, e.g. \chem{A \rightarrow B}.

The reaction environment creates labels including the letter R, i.e. (R1), (R2), etc.

- `\rightarrow` should be used for normal (one-way) chemical reactions

- `\rightleftharpoons` should be used for equilibria

- `\leftrightarrow` should be used for resonance structures

\begin{reaction}
A \rightarrow B \\
\end{reaction}
\begin{reaction}
Coper \rightleftharpoons nicus \\
\end{reaction}
\begin{reaction}
Publi \leftrightarrow cations
\end{reaction}

## PHYSICAL UNITS

Please use `\unit{}` (allows to save the math/`$` environment) and apply the exponential notation, for example \( 3.14\,\unit{km\,h^{-1}} \) (using LaTeX mode: `\( 3.14\,\unit{...} \)`) or \unit{0.872\,m\,s^{-1}} (using only `\unit{0.872\,m\,s^{-1}}`).

\conclusions

The conclusion goes here.
You can modify the section name with  `\conclusions[modified heading if necessary]`.
